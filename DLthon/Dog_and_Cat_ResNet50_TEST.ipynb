{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ZvfCVNXMbRN9U1gPpU84m6HmO2wcfg5d",
      "authorship_tag": "ABX9TyMPdntR5tkrKYaxS98M16ml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkmicheal1114/Python_Quest/blob/main/DLthon/Dog_and_Cat_ResNet50_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "Wn90HPkcPVGM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h2ZUs8OPK6D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D , BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "0zp1RU5nPXSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_paths = ['/content/drive/MyDrive/Colab Notebooks/study_dataset/dogs-vs-cats/train.zip' , '/content/drive/MyDrive/Colab Notebooks/study_dataset/dogs-vs-cats/test1.zip']  # 압축 파일의 경로와 파일명\n",
        "extract_dir = './content/dogs-vs-cats/'  # 압축 해제할 폴더의 경로와 이름\n",
        "\n",
        "for zip_path in zip_paths:\n",
        "  with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "PX9gyuLZPkAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 폴더 확인\n",
        "train_folder_path = './content/dogs-vs-cats/train'\n",
        "\n",
        "train_file_names = os.listdir(train_folder_path)\n",
        "print(\"train file name\" , train_file_names[:5] )\n",
        "print(\"train file numbers\" , len(train_file_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwsNZ2wtPl97",
        "outputId": "6cd570d4-0ecc-4a62-841b-d9b8e70ca14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train file name ['cat.10600.jpg', 'cat.6545.jpg', 'cat.9254.jpg', 'dog.7384.jpg', 'cat.2704.jpg']\n",
            "train file numbers 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 폴더 확인\n",
        "test_folder_path = './content/dogs-vs-cats/test1'\n",
        "\n",
        "test_file_names = os.listdir(test_folder_path)\n",
        "print(\"test file name\" , test_file_names[:5] )\n",
        "print(\"test file numbers\" , len(test_file_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoDe1jcUPoAj",
        "outputId": "43adf7a6-5f5c-45b2-8fe8-2caaffd93c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test file name ['4816.jpg', '11279.jpg', '10006.jpg', '3756.jpg', '7137.jpg']\n",
            "test file numbers 12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train dataframe\n",
        "\n",
        "targets = []\n",
        "full_paths = []\n",
        "train_cats_dir = []\n",
        "train_dogs_dir = []\n",
        "\n",
        "\n",
        "# Target setting\n",
        "for file_name in train_file_names:\n",
        "    target = file_name.split(\".\")[0] # target name\n",
        "    full_path = os.path.join(train_folder_path, file_name)\n",
        "\n",
        "    if(target == \"dog\"):\n",
        "        train_dogs_dir.append(full_path)\n",
        "    if(target == \"cat\"):\n",
        "        train_cats_dir.append(full_path)\n",
        "\n",
        "    full_paths.append(full_path)\n",
        "    targets.append(target)\n",
        "\n",
        "\n",
        "df_train = pd.DataFrame()\n",
        "df_train['image_path'] = full_paths\n",
        "df_train['target'] = targets"
      ],
      "metadata": {
        "id": "SzBr7NaSPqms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data dataframe\n",
        "full_paths = []\n",
        "file_names = []\n",
        "\n",
        "for file_name in test_file_names:\n",
        "    full_path = os.path.join(test_folder_path, file_name)\n",
        "\n",
        "    file_names.append(file_name)\n",
        "    full_paths.append(full_path)\n",
        "\n",
        "\n",
        "df_test = pd.DataFrame()\n",
        "df_test['image_path'] = full_paths\n",
        "df_test['filename'] = file_names"
      ],
      "metadata": {
        "id": "IMGHmGCxPuO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data , val_data = train_test_split(df_train, test_size=0.2, random_state=123)"
      ],
      "metadata": {
        "id": "MSGUkikYPyGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "print('학습 데이터 개수 ' , len(train_data))\n",
        "print('검증 데이터 개수 ' , len(val_data))\n",
        "\n",
        "plt.suptitle('Train Class Count')\n",
        "sns.countplot(data = df_train , x='target')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "y_16oZRcPz5n",
        "outputId": "36d7720d-e52c-4a34-f411-9c9ef9483264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 개수  20000\n",
            "검증 데이터 개수  5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='target', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 parameter Initialization\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256"
      ],
      "metadata": {
        "id": "Tw6Nrx-jP2ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess_input\n",
        "\n",
        "# DataGenrator 를 사용해서 Train , Val , Test data 를 생성 하도록 한다.\n",
        "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
        "                                     rotation_range=10,\n",
        "                                     width_shift_range=0.1,\n",
        "                                     height_shift_range=0.1,\n",
        "                                     zoom_range=0.1,\n",
        "                                     horizontal_flip=True,\n",
        "                                     preprocessing_function = resnet50_preprocess_input)\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_dataframe(batch_size = batch_size,\n",
        "                                                     dataframe = train_data,\n",
        "                                                     x_col = 'image_path',\n",
        "                                                     y_col = 'target',\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = val_datagen.flow_from_dataframe(batch_size = batch_size,\n",
        "                                                     dataframe = val_data,\n",
        "                                                     x_col = 'image_path',\n",
        "                                                     y_col = 'target',\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM0dWAw3P6qn",
        "outputId": "cd6f555d-4bc6-442c-fb17-7eb20060f311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 validated image filenames belonging to 2 classes.\n",
            "Found 5000 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "LdDX9nPiP91O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# callback 선언.\n",
        "from keras.callbacks import EarlyStopping , ReduceLROnPlateau\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, mode='min')\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr]\n"
      ],
      "metadata": {
        "id": "4bjqiaaYP7aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50 TransferLearning  ( conv5_1 )"
      ],
      "metadata": {
        "id": "3lIsoh1EQA9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras import models, layers\n",
        "\n",
        "# ResNet50 모델 불러오기\n",
        "resnet50 = ResNet50(input_shape=(IMG_HEIGHT,IMG_WIDTH,3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "# freeze_index 설정하기\n",
        "freeze_index = 143 # conv5_1 레이어의 인덱스\n",
        "\n",
        "# freeze_index 이전의 층은 고정하고, 이후의 층은 학습 가능하게 설정하기\n",
        "for layer in resnet50.layers[:freeze_index]:\n",
        "    layer.trainable = False\n",
        "for layer in resnet50.layers[freeze_index:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# 배치 정규화 레이어는 자동 조정 적용하기\n",
        "for layer in resnet50.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "\n",
        "# FC Layer 추가하기\n",
        "model = models.Sequential()\n",
        "model.add(resnet50)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "  train_data_gen,\n",
        "  steps_per_epoch= train_data.shape[0]/batch_size,\n",
        "  validation_steps= val_data.shape[0]/batch_size,\n",
        "  batch_size = batch_size,\n",
        "  epochs=epochs,\n",
        "  callbacks = callbacks,\n",
        "  validation_data= val_data_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "gjrJfV3vQAeU",
        "outputId": "a57d2d26-76c8-4250-d146-5d4a8473a931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "Epoch 1/15\n",
            "625/625 [==============================] - 531s 796ms/step - loss: 0.1410 - accuracy: 0.9707 - val_loss: 1.0484 - val_accuracy: 0.6808 - lr: 1.0000e-04\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - 480s 767ms/step - loss: 0.0487 - accuracy: 0.9858 - val_loss: 0.2609 - val_accuracy: 0.9560 - lr: 1.0000e-04\n",
            "Epoch 3/15\n",
            "625/625 [==============================] - 475s 760ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.1637 - val_accuracy: 0.9706 - lr: 1.0000e-04\n",
            "Epoch 4/15\n",
            "298/625 [=============>................] - ETA: 3:54 - loss: 0.0251 - accuracy: 0.9942"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-13e6dc9b52d4>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m               optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4), metrics=['accuracy'])\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0mtrain_data_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to_save('./content/dogs-vs-cats/resnet_ver1.h5')"
      ],
      "metadata": {
        "id": "TNqgcTOI_T5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "\n",
        "    axs[0].plot(range(1,len(model_history.history[acc])+1),model_history.history[acc])\n",
        "    axs[0].plot(range(1,len(model_history.history[val_acc])+1),model_history.history[val_acc])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "plot_model_history(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "I2Jq9No5RBsT",
        "outputId": "51022097-f9d5-405b-e2ce-9be753c61467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-12a6ca4d9d23>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mplot_model_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to_save('./content/dogs-vs-cats/resnet_ver2.h5')"
      ],
      "metadata": {
        "id": "l57-sEcF_Mib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50 TransferLearning  ( conv4_1 )"
      ],
      "metadata": {
        "id": "67voQAADRrOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras import models, layers\n",
        "\n",
        "# ResNet50 모델 불러오기\n",
        "resnet50 = ResNet50(input_shape=(IMG_HEIGHT,IMG_WIDTH,3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "# freeze_index 설정하기\n",
        "freeze_index = 79 # conv5_1 레이어의 인덱스\n",
        "\n",
        "# freeze_index 이전의 층은 고정하고, 이후의 층은 학습 가능하게 설정하기\n",
        "for layer in resnet50.layers[:freeze_index]:\n",
        "    layer.trainable = False\n",
        "for layer in resnet50.layers[freeze_index:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# 배치 정규화 레이어는 자동 조정 적용하기\n",
        "for layer in resnet50.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "\n",
        "# FC Layer 추가하기\n",
        "model = models.Sequential()\n",
        "model.add(resnet50)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-4), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "  train_data_gen,\n",
        "  steps_per_epoch= train_data.shape[0]/batch_size,\n",
        "  validation_steps= val_data.shape[0]/batch_size,\n",
        "  batch_size = batch_size,\n",
        "  epochs=epochs,\n",
        "  callbacks = callbacks,\n",
        "  validation_data= val_data_gen)"
      ],
      "metadata": {
        "id": "EgkPWIATRW4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model_history(history)"
      ],
      "metadata": {
        "id": "4r7-J6-iRly2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Data 평가\n",
        "\n",
        " - Label 데이터가 없어서 시각화로 표현"
      ],
      "metadata": {
        "id": "OSiiPKf_RxvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터처리.\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_data_gen = test_datagen.flow_from_dataframe(batch_size = batch_size,\n",
        "                                                     dataframe = df_test,\n",
        "                                                     x_col = 'image_path',\n",
        "                                                     y_col = 'target',\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')"
      ],
      "metadata": {
        "id": "ltLfqdVSRyWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 예측하기\n",
        "pred = model.predict(test_data_gen)\n",
        "\n",
        "# 임계값 적용하기\n",
        "predictions = (pred > 0.5).astype(int)\n",
        "df_test['pred']  = predictions"
      ],
      "metadata": {
        "id": "DoKt7t17R0qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# test 데이터 평가.\n",
        "fig = plt.figure(1, figsize=(20, 20))\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(Image.open(df_test.image_path[i]))\n",
        "    plt.title(f\"Predicted as {'dog' if predictions[i] == 1 else 'cat'} \\n Confidence : {round(100*(np.max(pred[i])), 2)}% \", fontsize=8)\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show"
      ],
      "metadata": {
        "id": "6vpSZve5R5pR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}